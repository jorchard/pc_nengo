{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c306d8",
   "metadata": {},
   "source": [
    "# Predictive Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf8d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nengo\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f28966b",
   "metadata": {},
   "source": [
    "# `PCLayer` class\n",
    "This class models both the value nodes and error nodes of a single layer, as well as their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9659ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCLayer(nengo.Network):\n",
    "    '''\n",
    "    l = PCLayer(n_nodes=10, tau=0.01)\n",
    "\n",
    "    Creates a layer for a predictive-coding network.\n",
    "    This layer has an array of value nodes, and a corresponding array of error nodes.\n",
    "\n",
    "    Inputs:\n",
    "    n_nodes       number of nodes in the layer\n",
    "    tau           synaptic time constant for internal error->value connections\n",
    "    pred_layer    is this a prediction layer\n",
    "    '''\n",
    "    def __init__(self, n_nodes=10, tau=0.01, pred_layer=False):\n",
    "        self.label = 'PCLayer'\n",
    "        self.n_nodes = n_nodes\n",
    "        self.pred_layer = pred_layer\n",
    "        self.tau = tau\n",
    "        self.inference_node = None\n",
    "\n",
    "        # When the network is run in using the \"Direct\" neuron model, it treats\n",
    "        # each \"Ensemble\" as a single variable, and the decodings are done by\n",
    "        # the user-supplied decoding functions, not using decoding weights.\n",
    "        # In this case, the \"n_neurons\" argument is ignored.\n",
    "\n",
    "        # An \"EnsembleArray\" can be thought of as a group of nodes.\n",
    "        # An EnsembleArray holding the values (v)\n",
    "        self.v = nengo.networks.EnsembleArray(n_neurons=50, n_ensembles=n_nodes, radius=1.5)\n",
    "        # and an EnsembleArray holding the errors (e)\n",
    "        self.e = nengo.networks.EnsembleArray(n_neurons=50, n_ensembles=n_nodes, radius=1.5)\n",
    "\n",
    "        #node in between e and v for inference\n",
    "\n",
    "        nengo.Connection(self.v.output, self.v.input, transform=1, synapse=tau)               # sustain old state\n",
    "\n",
    "        if self.pred_layer:\n",
    "            #self.delay = DelayOnce(n_nodes, timesteps=1)\n",
    "            self.pass_through = nengo.Node(self.step, size_in=n_nodes, size_out=n_nodes)   #pass-through node between (e) and (v)\n",
    "            nengo.Connection(self.e.output, self.pass_through, transform=1, synapse=tau)            # (v)<-(e)                                               \n",
    "            nengo.Connection(self.pass_through, self.v.input, transform=-1, synapse=tau) \n",
    "        else:           \n",
    "            nengo.Connection(self.e.output, self.v.input, transform=-1, synapse=tau)            \n",
    "        nengo.Connection(self.v.output, self.e.input, synapse=tau)                            # (v)->(e)\n",
    "\n",
    "    def step(self, t, x):\n",
    "        if t > 0 and self.inference_node.output(t) == 0: #simply pass through the input\n",
    "            return x\n",
    "        else:\n",
    "            if hasattr(x, '__len__'): #input with length\n",
    "                return [0 for i in range(len(x))]\n",
    "            else: #should just be an int or float\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d88e2",
   "metadata": {},
   "source": [
    "# `PCConnection` class\n",
    "This class models the weighted, all-to-all connections between `PCLayer`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfed26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Updater(nengo.Process):\n",
    "    \"\"\"\n",
    "    Extends the nengo.Process class to be used in the PCConnection class. \n",
    "    A PCConnection instance will create an Updater during initialization.\n",
    "\n",
    "    connection_class     The instance of the PCConnection class that created this Updater.\n",
    "    \"\"\"\n",
    "    def __init__(self, connection_class, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.connection_class = connection_class\n",
    "        self.shape_in = self.connection_class.n_e + self.connection_class.n_v\n",
    "        self.shape_out = self.connection_class.n_e + self.connection_class.n_v\n",
    "    \n",
    "    \n",
    "    def apply(x, dt=None, rng=np.random, **kwargs):\n",
    "        shape_in = x.shape\n",
    "        shape_out = x.shape\n",
    "        dt = self.default_dt if dt is None else dt\n",
    "        rng = self.get_rng(rng)\n",
    "        state = self.make_state(shape_in, shape_out, dt)\n",
    "        step = self.make_step(x, shape_in, shape_out, dt, rng, state, **kwargs)\n",
    "        return step(t)\n",
    "\n",
    "\n",
    "    def make_step(self, x, shape_in, shape_out, dt, rng, state):\n",
    "        \n",
    "        def step_updater(t):\n",
    "            e_in = x[:self.connection_class.n_e]\n",
    "            v_in = x[self.connection_class.n_e:]\n",
    "\n",
    "            err_out = self.connection_class.deriv(v_in) * (e_in @ self.connection_class.W)\n",
    "            pred_out = self.connection_class.func(v_in) @ self.connection_class.M\n",
    "\n",
    "            if self.connection_class.inference_node.output(t) == 0: #not doing inference, so we learn\n",
    "                dM = np.outer(self.connection_class.func(v_in), e_in)\n",
    "                #print(\"tau learn\", self.connection_class.tau_learn)\n",
    "                #print(\"dM\", dM)\n",
    "                #print(\"M\", self.M)\n",
    "                self.connection_class.M += dt* dM / self.connection_class.tau_learn\n",
    "                if not self.connection_class.symmetric:\n",
    "                    self.connection_class.W += dt * dM.T / self.connection_class.tau_learn\n",
    "\n",
    "            return np.concatenate((pred_out, err_out)) \n",
    "            \n",
    "        return step_updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bbb3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCConnection(nengo.Network):\n",
    "    '''\n",
    "     c = PCConnection(below, above, learn=False, symmetric=True)\n",
    "     \n",
    "     This class builds all the connections between the two PCLayers.\n",
    "     \n",
    "     Inputs:\n",
    "      below        PCLayer object below\n",
    "      above        PCLayer object above\n",
    "      learn        Boolean, whether to learn (default False)\n",
    "      symmetric    Boolean, whether the connection is symmetric\n",
    "                   ie. W = M.T (default True)\n",
    "      activation  Activation function to use. None defaults to linear\n",
    "    '''\n",
    "    def __init__(self, below, above, inference_node=None, tau_learn=20., symmetric=True, M=None, activation=None):\n",
    "        self.below = below\n",
    "        self.above = above\n",
    "        #self.learn = learn\n",
    "        self.tau_learn = tau_learn    # learning time constant\n",
    "        self.symmetric = symmetric\n",
    "        self.n_e = self.below.e.n_ensembles  # dimension of below layer\n",
    "        self.n_v = self.above.v.n_ensembles  # dimension of above layer\n",
    "\n",
    "        self.inference_node = inference_node #we will learn if and only if not doing inference\n",
    "\n",
    "        if activation is None: #Linear Activiation\n",
    "            self.func = lambda x: x\n",
    "            self.deriv = lambda x: np.ones_like(x)\n",
    "        elif activation==\"ReLU\":\n",
    "            self.func = lambda x: np.maximum(0, x)\n",
    "            self.deriv = lambda x: (np.sign(x)+1)/2\n",
    "        elif activation==\"logistic\":\n",
    "            self.func = lambda x: 1/(1 + np.exp(-x))\n",
    "            self.deriv = lambda x: self.func(x)*(1-self.func(x))\n",
    "        elif activation==\"tanh\":\n",
    "            self.func = lambda x: np.tanh(x)\n",
    "            self.deriv = lambda x: 1 - np.tanh(x)**2\n",
    "        elif activation==\"threshold\":\n",
    "            self.func = lambda x: (np.sign(x)+1)/2\n",
    "            self.deriv = lambda x: np.zeros_like(x)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown activation function. Acceptable inputs are: None, \"\n",
    "                             + \"\\\"ReLU\\\", \"\n",
    "                             + \"\\\"logistic\\\", \"\n",
    "                             + \"\\\"tanh\\\", \"\n",
    "                             + f\"or \\\"threshold\\\". Got \\\"{activation}\\\".\")\n",
    "\n",
    "\n",
    "        # Set up connect matrices\n",
    "        if M is None:\n",
    "            self.M = np.random.normal(size=(self.n_v, self.n_e))/10.\n",
    "        else:\n",
    "            self.M = M\n",
    "        if self.symmetric:\n",
    "            self.W = self.M.T\n",
    "        else:\n",
    "            self.W = np.random.normal(size=(self.n_e, self.n_v))\n",
    "        \n",
    "        # Set up the node that applies the connection weights\n",
    "        dims = self.n_e + self.n_v\n",
    "        #self.exchange = nengo.Node(Updater(self), size_in=dims, size_out=dims)\n",
    "        self.exchange = nengo.Node(self.update, size_in=dims, size_out=dims)\n",
    "        \n",
    "\n",
    "        n = self.n_e\n",
    "        nengo.Connection(self.below.e.output, self.exchange[:n])               # inp -> exchange\n",
    "        nengo.Connection(self.exchange[:n], self.below.e.input, transform=-1)  # inp <- con\n",
    "        nengo.Connection(self.above.v.output, self.exchange[n:], transform=1)  # con <- hid\n",
    "        nengo.Connection(self.exchange[n:], self.above.v.input)                # con -> hid\n",
    "        \n",
    "    def update(self, t, x):\n",
    "        \"\"\"\n",
    "        # Original update rule without nonlinearity\n",
    "        e_in = x[:self.n_e]\n",
    "        v_in = x[self.n_e:]\n",
    "\n",
    "        err_out = self.deriv(v_in) * (self.W @ e_in)\n",
    "        pred_out = self.M @ self.func(v_in)\n",
    "\n",
    "        if self.learn:\n",
    "            dM = np.outer(e_in, self.func(v_in))\n",
    "            self.M += dM / self.tau_learn\n",
    "            if not self.symmetric:\n",
    "                self.W += dM.T / self.tau_learn\n",
    "\n",
    "        return np.concatenate((pred_out, err_out))\n",
    "        \"\"\"\n",
    "        e_in = x[:self.n_e]\n",
    "        v_in = x[self.n_e:]\n",
    "\n",
    "        err_out = self.deriv(v_in) * (e_in @ self.W)\n",
    "        pred_out = self.func(v_in) @ self.M\n",
    "\n",
    "        if self.inference_node.output(t) == 0: #not doing inference, so we learn\n",
    "            dM = np.outer(self.func(v_in), e_in)\n",
    "            #print(\"tau learn\", self.tau_learn)\n",
    "            #print(\"dM\", dM)\n",
    "            #print(\"M\", self.M)\n",
    "            self.M += dM / self.tau_learn\n",
    "            if not self.symmetric:\n",
    "                self.W += dM.T / self.tau_learn\n",
    "\n",
    "        return np.concatenate((pred_out, err_out))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de7cff0",
   "metadata": {},
   "source": [
    "# `PCNetwork` class\n",
    "This class creates a predictive coding neural network made of `PCLayer`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef184e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCNetwork:\n",
    "    '''\n",
    "    This class builds a PC neural network with.\n",
    "    \n",
    "    Inputs:\n",
    "    n_nodes               List, the of number of nodes at each hidden layer\n",
    "    learn                 Boolean, whether to learn (default False)\n",
    "    symmetric             Boolean, whether the connection is symmetric\n",
    "                          ie. W = M.T (default True)\n",
    "    tau_learn             num or List, learning rate for the Euler step when updating the weights\n",
    "                            - if num, each connection will have the same tau_learn\n",
    "                            - if List, each connection will have a tau_learn corresponding to the value in that\n",
    "                              position in the list\n",
    "    M                     ndarray, List or None, value of M at each layer, defaults to None\n",
    "                            - if ndarray or None, each connection will have M passed in as an argument during construction\n",
    "                            - if List, each connection will have an M corresponding to the value in that\n",
    "                              position in the list\n",
    "    activation            None, string, or list, defaults to None\n",
    "                            - if string or None, each connection will have the same activation function\n",
    "                            - if list, each connection will have an activation fucntion corresponding to the value\n",
    "                              in that position in the list\n",
    "    t                     Num, the amount of simulation time to spend learning connection weights, defaults to 0\n",
    "    '''\n",
    "    def __init__(self, n_nodes=None, symmetric=True, tau_learn=10., M=None, activation=None, t=0):\n",
    "        if n_nodes is None:\n",
    "            n_nodes = []\n",
    "        elif type(n_nodes) is not list:\n",
    "            raise TypeError(f\"n_nodes must be a list or an int, instead got {type(n_nodes)}\")\n",
    "        else:\n",
    "            self.n_nodes = n_nodes\n",
    "        self.num_hidden_layers = len(self.n_nodes)\n",
    "        self.layers = [] #a list of all layers in order of connection\n",
    "        self.connections = [] #a list of all connections between layers\n",
    "        self.symmetric = symmetric\n",
    "        self.t = t\n",
    "        self.inference_node = nengo.Node(self.inference_output)\n",
    "\n",
    "        #set up member attributes and input validation\n",
    "        if type(tau_learn) is int or type(tau_learn) is float:\n",
    "            self.tau_learn = [tau_learn for i in range(self.num_hidden_layers-1)]   # learning time constant\n",
    "        elif type(tau_learn) is not list:\n",
    "            raise TypeError(f\"tau_learn must be a list or an int/float, instead got {type(tau_learn)}\")\n",
    "        else:\n",
    "            if len(tau_learn) != self.num_hidden_layers-1:\n",
    "                raise ValueError(f\"If tau is a list, it must have {self.num_hidden_layers-1}, instead got {len(tau_learn)}\")\n",
    "            self.tau_learn = tau_learn\n",
    "  \n",
    "        if type(M) is np.ndarray or M is None:\n",
    "            self.M = [M for i in range(self.num_hidden_layers-1)]\n",
    "        elif type(M) is not list:\n",
    "            raise TypeError(f\"M must be an ndarray, list, or None, instead got {type(M)}\")\n",
    "        else:\n",
    "            if len(M) != self.num_hidden_layers-1:\n",
    "                raise ValueError(f\"If M is a list, it must have {self.num_hidden_layers-1} elements, instead got {len(M)}\")\n",
    "            self.M = M\n",
    "        \n",
    "        if type(activation) is str or activation is None:\n",
    "            self.activation = [activation for i in range(self.num_hidden_layers-1)]\n",
    "        elif type(activation) is not list:\n",
    "            raise TypeError(f\"activation must be a list, string, or None, instead got {type(activation)}\")\n",
    "        else:\n",
    "            if len(activation) != self.num_hidden_layers-1:\n",
    "                raise ValueError(f\"If activation is a list, it must have {self.num_hidden_layers-1} elements, instead got {len(activation)}\")\n",
    "            self.activation = activation\n",
    "        \n",
    "        #create hidden layers\n",
    "        self.layers.append(PCLayer(n_nodes=self.n_nodes[0]))\n",
    "        for i in range(1, self.num_hidden_layers-1): #create and connect the rest of the layers\n",
    "            self.layers.append(PCLayer(n_nodes=self.n_nodes[i]))\n",
    "            self.connections.append(PCConnection(self.layers[i-1], \n",
    "                                                 self.layers[i], \n",
    "                                                 inference_node=self.inference_node, \n",
    "                                                 symmetric=self.symmetric,\n",
    "                                                 M=self.M[i-1],\n",
    "                                                 tau_learn=self.tau_learn[i-1],\n",
    "                                                 activation=self.activation[i-1]))\n",
    "        #prediction layer\n",
    "        self.layers.append(PCLayer(n_nodes=self.n_nodes[-1], pred_layer=True))\n",
    "        self.connections.append(PCConnection(self.layers[-2], \n",
    "                                                self.layers[-1], \n",
    "                                                inference_node=self.inference_node, \n",
    "                                                symmetric=self.symmetric,\n",
    "                                                M=self.M[-1],\n",
    "                                                tau_learn=self.tau_learn[-1],\n",
    "                                                activation=self.activation[-1]))\n",
    "            \n",
    "\n",
    "    def inference_output(self, time):\n",
    "        if time < self.t: #not inference, training\n",
    "            return 0\n",
    "        else: #inference\n",
    "            return 1\n",
    "            \n",
    "    def connect_input(self, stim):\n",
    "        \"\"\" (self, nengo.Node) -> ()\n",
    "        Connects the input (stimulus) layer to the first hidden layer of the network.\n",
    "        \"\"\"\n",
    "        D = stim.size_out #dimensionality of inputs to the the network\n",
    "        \n",
    "        if self.n_nodes[0] != D:\n",
    "            raise ValueError(\"Dimensionality of the input does not match the dimensionality of the first layer.\")\n",
    "        \n",
    "        stim_err = nengo.Node(lambda t,x: x[:D]+x[D:], size_in=2*D, size_out=D)  # sensory error\n",
    "        nengo.Connection(stim, stim_err[:D])                                 # stim -> stim_err\n",
    "        nengo.Connection(stim_err, self.layers[0].v.input)                   # stim_err -> first layer\n",
    "        nengo.Connection(self.layers[0].v.output, stim_err[D:], transform=-1) # stim_err <- first layer\n",
    "\n",
    "    \n",
    "\n",
    "    def connect_output(self, pred):\n",
    "        \"\"\" (self, nengo.Node, num) -> ()\n",
    "        Connects the output (prediction) layer to the last hidden layer of the network. \n",
    "        \"\"\"\n",
    "        if self.n_nodes[-1] != pred.size_out:\n",
    "            raise ValueError(\"Dimensionality of the target does not match the dimensionality of the last layer.\")\n",
    "         \n",
    "        self.layers[-1].inference_node = self.inference_node\n",
    "        nengo.Connection(pred, self.layers[-1].e.input, transform=-1)         # pc2 <- pred\n",
    "    \n",
    "\n",
    "    def update_learning_rule(self, learning_rule):\n",
    "        \"\"\" (self, bool) -> ()\n",
    "        Changes the learning rule for each connection is self.connections to learning_rule\n",
    "        \"\"\"\n",
    "        for con in self.connections:\n",
    "            con.learn = learning_rule\n",
    "\n",
    "    \n",
    "    def get_probes(self):\n",
    "        \"\"\" (self) -> (list, list)\n",
    "        Returns a list of nengo.Probes to track each layers values and errors.\n",
    "\n",
    "        ##### NOT GREAT WHEN DIMENSIONALITY OF INPUT IS MORE THAN 1\n",
    "        \"\"\"\n",
    "        val_probes = []\n",
    "        err_probes = []\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            val_probes.append(nengo.Probe(layer.v.output, label=f\"Hidden Layer {idx} Value\"))\n",
    "            err_probes.append(nengo.Probe(layer.e.output, label=f\"Hidden Layer {idx} Error\"))\n",
    "        return val_probes, err_probes\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "537d053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same test as before but using the PCNetwork class\n",
    "n = 1\n",
    "with nengo.Network() as net:\n",
    "    tau = 0.001\n",
    "    #============== Run in Direct mode =======================\n",
    "    net.config[nengo.Ensemble].neuron_type = nengo.Direct()\n",
    "    #=========================================================\n",
    "    net.config[nengo.Connection].synapse = tau\n",
    "    net.config[nengo.Probe].synapse = 0.05\n",
    "    \n",
    "    # Inputs\n",
    "    stim = nengo.Node([1, 2])   # sensory (bottom layer)\n",
    "    pred = nengo.Node([0.5, 3])  # percept (top layer)\n",
    "\n",
    "    \n",
    "    # PC layers\n",
    "    PC_net = PCNetwork(n_nodes=[2, 5, 2], tau_learn=100, symmetric=True, t=2)\n",
    "    PC_net.connect_input(stim=stim)\n",
    "    PC_net.connect_output(pred)\n",
    "    '''\n",
    "     [     /-->         ] -W-> [      /-->       ] -W-> [      /-->       ]      [      ]\n",
    "     [ stim     stim_err]      [ pc1.v     pc1.e ]      [ pc2.v     pc2.e ]      [ pred ]\n",
    "     [                  ] <-M- [       <--/      ] <-M- [       <--/      ] <-M- [      ]\n",
    "    '''\n",
    "    \n",
    " \n",
    "    # Set up a bunch of probes (so we can plot stuff later)\n",
    "    p_stim = nengo.Probe(stim)\n",
    "    p_pc1v = nengo.Probe(PC_net.layers[0].v.output)\n",
    "    p_pc1e = nengo.Probe(PC_net.layers[0].e.output)\n",
    "    p_pc_end_v = nengo.Probe(PC_net.layers[-1].v.output)\n",
    "    p_pc_end_e = nengo.Probe(PC_net.layers[-1].e.output)\n",
    "    p_pred = nengo.Probe(pred)\n",
    "\n",
    "    val_probes, err_probes = PC_net.get_probes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11176170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build finished in 0:00:01.                                                      \n"
     ]
    }
   ],
   "source": [
    "sim = nengo.Simulator(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ff5b6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished in 0:00:02.                                                 \n"
     ]
    }
   ],
   "source": [
    "sim.run(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "ax[0].plot(sim.trange(), sim.data[p_pc1v]);\n",
    "ax[1].plot(sim.trange(), sim.data[p_pc1e]);\n",
    "ax[0].plot(sim.trange(), sim.data[p_pc_end_v]);\n",
    "ax[1].plot(sim.trange(), sim.data[p_pc_end_e]);\n",
    "ax[0].plot(sim.trange(), sim.data[p_stim], ':');\n",
    "ax[0].plot(sim.trange(), sim.data[p_pred], \"--\");\n",
    "ax[0].legend(['pc1_v[0]', 'pc1_v[1]', 'pc2_v[0]', 'pc2_v[1]', 'stim[0]', 'stim[1]', 'pred[0]', 'pred[1]'],\n",
    "             loc='upper right', bbox_to_anchor=(1, 1.5));\n",
    "ax[1].legend(['pc1_e[0]', 'pc1_e[1]', 'pc2_e[0]', 'pc2_e[1]'],\n",
    "             loc='upper left', bbox_to_anchor=(0.6, 1.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "ax[0].plot(sim.trange(), sim.data[p_pc1v]);\n",
    "ax[1].plot(sim.trange(), sim.data[p_pc1e]);\n",
    "ax[0].plot(sim.trange(), sim.data[p_pc_end_v]);\n",
    "ax[1].plot(sim.trange(), sim.data[p_pc_end_e]);\n",
    "ax[0].plot(sim.trange(), sim.data[p_stim], ':');\n",
    "ax[0].plot(sim.trange(), sim.data[p_pred], \"--\");\n",
    "ax[0].legend(['pc1_v[0]', 'pc1_v[1]', 'pc2_v[0]', 'pc2_v[1]', 'stim[0]', 'stim[1]', 'pred[0]', 'pred[1]'],\n",
    "             loc='upper right', bbox_to_anchor=(1, 1.5));\n",
    "ax[1].legend(['pc1_e[0]', 'pc1_e[1]', 'pc2_e[0]', 'pc2_e[1]'],\n",
    "             loc='upper left', bbox_to_anchor=(0.6, 1.2));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731fddcd",
   "metadata": {},
   "source": [
    "# Learning Multiple Inputs\n",
    "\n",
    "Given a dataset (X, Y), we want to create two dictionaries that we can pass into a nengo.processes.Piecewise object. This means that the keys must be numbers specifying the time at which to start outputting the corresponding values. The first dictionary will hold the input data, X, and the second will hold the targets, Y. We should be able to specify:\n",
    "* The number of epochs to go over the dataset\n",
    "* The amount of time to spend at each datapoint, subdivided into the amount of time spent stabilizing and the amount of time spent learning\n",
    "\n",
    "What do we do about inference? Here we run into the same problem as we did with the prediction layer. We already have a node connected to the input layer giving inputs. We need to change these inputs if we want to do inference on other objects we have not seen yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd00fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_learning_inputs(X, Y, epochs, stabilize_time, learn_time, shuffle=True):\n",
    "    \"\"\" (np.array, np.array, int, num, num) -> (dict, dict, num)\n",
    "\n",
    "    X                   Numpy array, datapoints to use as sensory input. Each row is a datapoint, the columns are features.\n",
    "    Y                   Numpy array, targets for perception corresponding to each datapoint. Each row is a given observation's target.\n",
    "    epochs              Int, the number of times to run through the dataset.\n",
    "    stablize_time       Num, the amount of simulation time to spend at each datapoint without learning.\n",
    "    learn_time          Num, the amount of simulation time to spend at each datapoint with learning.\n",
    "    shuffle             Boolean, whether or not to shuffle the dataset at each epoch. Defaults to True.\n",
    "\n",
    "    Returns\n",
    "    x_dict              Dict, contains the data inputs.\n",
    "    y_dict              Dict, contains the target vectors.\n",
    "    t                   Num, the total simulation time for learning.\n",
    "    \"\"\"\n",
    "    #our dictionaries to return\n",
    "    x_dict = {}\n",
    "    y_dict = {}\n",
    "\n",
    "    #size of the dataset\n",
    "    if len(X.shape) == 1:\n",
    "        num_points = X.shape[0]\n",
    "        num_features = 1\n",
    "    else:\n",
    "        num_points, num_features = X.shape\n",
    "    #the size of the targets\n",
    "    if len(Y.shape) == 1: #one-dimensional ouputs\n",
    "        target_dimensions = 1 \n",
    "    else:\n",
    "        target_dimensions = Y.shape[1] \n",
    "\n",
    "    t = 0 #keep track of the simulation time\n",
    "    point_time = stabilize_time + learn_time #the total amount of time to spend at one point\n",
    "\n",
    "    indices = np.arange(num_points) #the indices of the datapoints\n",
    "\n",
    "    for e in range(epochs):\n",
    "        if shuffle: #shuffle the dataset each epoch\n",
    "            np.random.shuffle(indices)\n",
    "        for i in indices:\n",
    "            if num_features == 1:\n",
    "                x_dict[t] = X[i]\n",
    "            else:\n",
    "                x_dict[t] = X[i,:]\n",
    "            if target_dimensions == 1:\n",
    "                y_dict[t] = Y[i]\n",
    "            else:\n",
    "                y_dict[t] = Y[i,:]\n",
    "            \n",
    "            t += point_time #increment the time step\n",
    "    \n",
    "    return x_dict, y_dict, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(sim, pc_net, stabilize_time, learn_time, t):\n",
    "    \"\"\" (nengo.Simulator, PCNetwork, num, num, num) -> ()\n",
    "\n",
    "    pc_net              PCNetwork, the network we wish to train.\n",
    "    sim                 nengo.Simulator, the simulator created using the network we wish to train.\n",
    "    stablize_time       Num, the amount of simulation time to spend at each data point without learning.\n",
    "    learn_time          Num, the amount of simulation time to spend at each data point with learning.\n",
    "    t                   Num, the total simulation time.\n",
    "\n",
    "    \"\"\"\n",
    "    sim.run(t)\n",
    "    \"\"\"\n",
    "    time = 0 #keep track of current time\n",
    "    while time < t:\n",
    "        pc_net.update_learning_rule(False)\n",
    "        sim.run(stabilize_time)\n",
    "        pc_net.update_learning_rule(True)\n",
    "        sim.run(learn_time) \n",
    "        time += stabilize_time + learn_time\n",
    "    pc_net.update_learning_rule(False) #set the network to not learn anymore\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCNetwork class\n",
    "n = 1\n",
    "with nengo.Network() as net:\n",
    "    tau = 0.01\n",
    "    #============== Run in Direct mode =======================\n",
    "    net.config[nengo.Ensemble].neuron_type = nengo.Direct()\n",
    "    #=========================================================\n",
    "    net.config[nengo.Connection].synapse = tau\n",
    "    net.config[nengo.Probe].synapse = 0.05\n",
    "    \n",
    "    # Inputs\n",
    "    D = 2\n",
    "    stab = 0\n",
    "    learn = 5\n",
    "    # our 'raw' data\n",
    "    x_data = np.array([[1, 0.5],[1.5, 2]])\n",
    "    y_data = np.array([[0.25, 0.8], [-1, 0]])\n",
    "    #create the dictionaries to pass into the piecewise functiona\n",
    "    x_input, y_input, t = create_learning_inputs(x_data, y_data, 5, stab, learn, shuffle=True)\n",
    "    #hardcode the inference phase\n",
    "    x_input[t] = [1, 0.5]\n",
    "    x_input[t+5] = [1.5, 2]\n",
    "    y_input[t] = [0.25, 0.8]\n",
    "    y_input[t+5] = [-1, 0]\n",
    "    \n",
    "    stim = nengo.Node(nengo.processes.Piecewise(x_input))   # sensory (bottom layer)\n",
    "    pred = nengo.Node(nengo.processes.Piecewise(y_input))  # percept (top layer)\n",
    "    \n",
    "    # PC layers\n",
    "    PC_net = PCNetwork(n_nodes=[2, 7, 10, 7, 2], tau_learn=400, symmetric=True, activation=\"logistic\", t=t)\n",
    "    PC_net.connect_input(stim=stim)\n",
    "    PC_net.connect_output(pred)\n",
    "    '''\n",
    "     [     /-->         ] -W-> [      /-->       ] -W-> [      /-->       ]      [      ]\n",
    "     [ stim     stim_err]      [ pc1.v     pc1.e ]      [ pc2.v     pc2.e ]      [ pred ]\n",
    "     [                  ] <-M- [       <--/      ] <-M- [       <--/      ] <-M- [      ]\n",
    "    '''\n",
    "    \n",
    " \n",
    "    # Set up a bunch of probes (so we can plot stuff later)\n",
    "    p_stim = nengo.Probe(stim)\n",
    "    p_pc1v = nengo.Probe(PC_net.layers[0].v.output)\n",
    "    p_pc1e = nengo.Probe(PC_net.layers[0].e.output)\n",
    "    p_pc_end_v = nengo.Probe(PC_net.layers[-1].v.output)\n",
    "    p_pc_end_e = nengo.Probe(PC_net.layers[-1].e.output)\n",
    "    p_pred = nengo.Probe(pred)\n",
    "\n",
    "    val_probes, err_probes = PC_net.get_probes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_network(sim, PC_net, stab, learn, t)\n",
    "sim.run(10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295d1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,7))\n",
    "\n",
    "ax[0].plot(sim.trange(), sim.data[p_pc1v]);\n",
    "ax[1].plot(sim.trange(), sim.data[p_pc1e]);\n",
    "ax[0].plot(sim.trange(), sim.data[p_pc_end_v]);\n",
    "ax[1].plot(sim.trange(), sim.data[p_pc_end_e]);\n",
    "ax[0].plot(sim.trange(), sim.data[p_stim], ':');\n",
    "ax[0].plot(sim.trange(), sim.data[p_pred], \"--\");\n",
    "ax[0].legend(['pc1_v[0]', 'pc1_v[1]', 'pc2_v[0]', 'pc2_v[1]', 'stim[0]', 'stim[1]', 'pred[0]', 'pred[1]'],\n",
    "             loc='upper right', bbox_to_anchor=(1, 1.5));\n",
    "ax[1].legend(['pc1_e[0]', 'pc1_e[1]', 'pc2_e[0]', 'pc2_e[1]'],\n",
    "             loc='upper left', bbox_to_anchor=(0.6, 1.2));\n",
    "\n",
    "print(f\"Inference starts at t={t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914c503",
   "metadata": {},
   "source": [
    "### Copying Network Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "with nengo.Network() as net_inference:\n",
    "    tau = 0.01\n",
    "    #============== Run in Direct mode =======================\n",
    "    net.config[nengo.Ensemble].neuron_type = nengo.Direct()\n",
    "    #=========================================================\n",
    "    net.config[nengo.Connection].synapse = tau\n",
    "    net.config[nengo.Probe].synapse = 0.05\n",
    "    \n",
    "    # Inputs\n",
    "    stim = nengo.Node([1, 2])   # sensory (bottom layer)\n",
    "    pred = nengo.Node([0.5, 3])  # percept (top layer)\n",
    "\n",
    "    PC_net2 = PCNetwork(3, learn=False, tau_learn=100, n_nodes=[2, 5, 2], symmetric=True)\n",
    "    PC_net2.connect_input(stim=stim)\n",
    "\n",
    "    #copy connection weights over\n",
    "    for idx, connection in enumerate(PC_net2.connections):\n",
    "        connection.M = deepcopy(PC_net.connections[idx].M)\n",
    "        connection.W = deepcopy(PC_net.connections[idx].W)\n",
    "\n",
    "    p_stim = nengo.Probe(stim)\n",
    "    p_pred = nengo.Probe(pred)\n",
    "\n",
    "    val_probes, err_probes = PC_net2.get_probes()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eef234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = nengo.Simulator(net_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_net2.update_learning_rule(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run(10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d194db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "ax[0].plot(sim.trange(), sim.data[val_probes[0]]);\n",
    "ax[1].plot(sim.trange(), sim.data[err_probes[0]]);\n",
    "ax[0].plot(sim.trange(), sim.data[val_probes[-1]]);\n",
    "ax[1].plot(sim.trange(), sim.data[err_probes[-1]]);\n",
    "\n",
    "ax[0].plot(sim.trange(), sim.data[p_stim], ':');\n",
    "ax[0].plot(sim.trange(), sim.data[p_pred], \"--\");\n",
    "\n",
    "labels = [val_probes[i].label for i in range(len(val_probes))]\n",
    "labels.extend(['stim[0]', 'stim[1]', 'pred[0]', 'pred[1]'])\n",
    "ax[0].legend(['1st layer[0]', '1st layer[1]', 'last layer[0]', 'last layer[1]', 'stim[0]', 'stim[1]', 'pred[0]', 'pred[1]'],\n",
    "             loc='upper right', bbox_to_anchor=(1, 1.5));\n",
    "ax[1].legend([err_probes[i].label for i in range(len(err_probes))],\n",
    "             loc='upper left', bbox_to_anchor=(0.6, 1.2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fc676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
